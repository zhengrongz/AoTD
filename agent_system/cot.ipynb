{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2   \n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import sys\n",
    "sys.argv = ['main.py']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "\n",
    "setup_seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a3495f46fa44c6b4bb607af8f76c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a120f73f3a42ccb443971896dda44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabe3c5a915943d2b18297507634879e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 05:32:30.634:INFO:UniVTG.main.config - setup model/optimizer/scheduler\n",
      "2025-04-04 05:32:32.098:INFO:UniVTG.main.config - CUDA enabled.\n",
      "2025-04-04 05:32:32.108:INFO:UniVTG.main.config - Load checkpoint from pretrained_models/UniVTG/model_best.ckpt\n",
      "2025-04-04 05:32:40.054:INFO:UniVTG.main.config - Loaded model saved at epoch 14 from checkpoint: pretrained_models/UniVTG/model_best.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['deepseek', 'llama', 'llava', 'owlv2', 'univtg'])\n"
     ]
    }
   ],
   "source": [
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"your_path_to/video\"\n",
    "query = \"your_question\"\n",
    "possible_answers = ['choice A', 'choice B', '...']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decord\n",
    "import numpy as np\n",
    "from decord import cpu, gpu\n",
    "def get_video(video_path):\n",
    "    video_reader = decord.VideoReader(str(video_path), num_threads=1, ctx=cpu(0))\n",
    "    decord.bridge.set_bridge('torch')\n",
    "    vlen = len(video_reader)\n",
    "    fps = video_reader.get_avg_fps()\n",
    "    frame_idxs = np.linspace(0, vlen, 32, endpoint=False).astype(int)\n",
    "    video = video_reader.get_batch(frame_idxs).byte()\n",
    "    clip_len = vlen / (32 * fps)\n",
    "\n",
    "    return video, fps\n",
    "\n",
    "video, fps= get_video(video_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def execute_command(video_clip, query, possible_answers, time_wait_between_lines, syntax):\n",
      "    eat_clip = Filter_frames_with_act(video_clip, \"person is eating\")\n",
      "    person_clip = Find(eat_clip, \"person\")\n",
      "    clip_summary = Video_summary(person_clip, query)\n",
      "    eat_objs = Query_Objs(person_clip, \"object eaten by the person\", possible_answers)\n",
      "    objects_look_for = ['sandwich','medicine', 'blanket', 'box']\n",
      "    detected_objs = [obj_name for obj_name in objects_look_for if exist(eat_clip, obj_name)]\n",
      "    not_found = list(set(objects_look_for) - set(detected_objs))\n",
      "    info = {\n",
      "        \"object eaten by the person\": eat_objs,\n",
      "        \"objects in the video\": f'found: {detected_objs}, not found: {not_found}',\n",
      "        \"summary of the target video\": clip_summary\n",
      "    }\n",
      "    answer = select_answer(query, info, possible_answers)\n",
      "    return answer\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"def execute_command(video_clip, query, possible_answers, time_wait_between_lines, syntax):\\n    eat_clip = Filter_frames_with_act(video_clip, 'person is eating')\\n    person_clip = Find(eat_clip, 'person')\\n    clip_summary = Video_summary(person_clip, query)\\n    eat_objs = Query_Objs(person_clip, 'object eaten by the person', possible_answers)\\n    objects_look_for = ['sandwich', 'medicine', 'blanket', 'box']\\n    detected_objs = [obj_name for obj_name in objects_look_for if exist(eat_clip, obj_name)]\\n    not_found = list(set(objects_look_for) - set(detected_objs))\\n    info = {'object eaten by the person': eat_objs, 'objects in the video': f'found: {detected_objs}, not found: {not_found}', 'summary of the target video': clip_summary}\\n    answer = select_answer(query, info, possible_answers)\\n    return answer\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = get_code(query, possible_answers, input_type='video_clip, query, possible_answers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in llava model: list index out of range\n",
      "Error in llava model: list index out of range\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = execute_code(code, video, query=query, possible_answers=possible_answers)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aotd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
